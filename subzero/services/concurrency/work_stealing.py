"""
Copyright (c) 2025 Subzero Contributors
SPDX-License-Identifier: MIT

Work-Stealing Thread Pool for Optimal CPU Utilization
Inspired by Java's ForkJoinPool and Go's goroutine scheduler

Based on "Python Concurrency with asyncio" (Fowler)
Following patterns from "Designing Data-Intensive Applications" (Kleppmann)

Features:
- Per-CPU work queues with work-stealing
- Task affinity for cache locality
- Exponential backoff for idle threads
- Dynamic load balancing
- NUMA awareness (when available)
"""

import asyncio
import multiprocessing
import os
import random
import time
from collections import deque
from concurrent.futures import Future, ProcessPoolExecutor
from dataclasses import dataclass
from enum import Enum
from typing import Any, Callable, Optional


class TaskPriority(Enum):
    """Task priority levels"""

    LOW = 0
    NORMAL = 1
    HIGH = 2
    CRITICAL = 3


@dataclass
class WorkItem:
    """Work item in queue"""

    task_id: str
    func: Callable
    args: tuple
    kwargs: dict
    priority: TaskPriority
    affinity: Optional[int]  # Preferred CPU
    future: Future
    enqueue_time: float


class WorkQueue:
    """
    Lock-free work queue for single CPU
    Uses deque with local/remote access patterns
    """

    def __init__(self, cpu_id: int):
        self.cpu_id = cpu_id

        # Double-ended queue for LIFO (local) and FIFO (steal)
        self.deque: deque[WorkItem] = deque()

        # Statistics
        self.stats = {
            "local_pushes": 0,
            "local_pops": 0,
            "steals": 0,
            "stolen_from": 0,
        }

    def push_local(self, item: WorkItem):
        """Push to local end (LIFO for cache locality)"""
        self.deque.append(item)
        self.stats["local_pushes"] += 1

    def pop_local(self) -> Optional[WorkItem]:
        """Pop from local end (LIFO)"""
        try:
            item = self.deque.pop()
            self.stats["local_pops"] += 1
            return item
        except IndexError:
            return None

    def steal(self) -> Optional[WorkItem]:
        """Steal from remote end (FIFO for fairness)"""
        try:
            item = self.deque.popleft()
            self.stats["steals"] += 1
            return item
        except IndexError:
            return None

    def size(self) -> int:
        """Get queue size"""
        return len(self.deque)


class WorkStealingWorker:
    """
    Worker thread that processes tasks and steals work when idle
    """

    def __init__(self, worker_id: int, num_workers: int, queues: list[WorkQueue]):
        self.worker_id = worker_id
        self.num_workers = num_workers
        self.queues = queues
        self.my_queue = queues[worker_id]

        # Steal attempts with exponential backoff
        self.backoff_base_ms = 1
        self.backoff_max_ms = 100
        self.current_backoff_ms = self.backoff_base_ms

        # Worker statistics
        self.stats = {
            "tasks_processed": 0,
            "tasks_stolen": 0,
            "idle_time_ms": 0,
            "busy_time_ms": 0,
        }

        self.is_running = False

    async def run(self):
        """Main worker loop"""
        self.is_running = True

        while self.is_running:
            # Try to get work from local queue (LIFO for cache locality)
            work_item = self.my_queue.pop_local()

            if work_item:
                # Reset backoff
                self.current_backoff_ms = self.backoff_base_ms

                # Execute task
                start_time = time.time()
                await self._execute_task(work_item)
                execution_time_ms = (time.time() - start_time) * 1000

                self.stats["tasks_processed"] += 1
                self.stats["busy_time_ms"] += execution_time_ms

            else:
                # No local work, try stealing
                stolen_item = await self._try_steal_work()

                if stolen_item:
                    # Successfully stole work
                    self.current_backoff_ms = self.backoff_base_ms

                    start_time = time.time()
                    await self._execute_task(stolen_item)
                    execution_time_ms = (time.time() - start_time) * 1000

                    self.stats["tasks_processed"] += 1
                    self.stats["tasks_stolen"] += 1
                    self.stats["busy_time_ms"] += execution_time_ms

                else:
                    # No work available, backoff
                    idle_start = time.time()
                    await asyncio.sleep(self.current_backoff_ms / 1000)
                    idle_duration_ms = (time.time() - idle_start) * 1000

                    self.stats["idle_time_ms"] += idle_duration_ms

                    # Exponential backoff
                    self.current_backoff_ms = min(self.current_backoff_ms * 2, self.backoff_max_ms)

    async def _try_steal_work(self) -> Optional[WorkItem]:
        """
        Try to steal work from other queues

        Strategy:
        1. Random victim selection
        2. Try multiple victims before giving up
        """
        # Try stealing from random victims
        max_attempts = min(4, self.num_workers - 1)
        attempts = 0

        while attempts < max_attempts:
            # Pick random victim (not self)
            victim_id = random.randint(0, self.num_workers - 1)
            if victim_id == self.worker_id:
                continue

            # Try to steal
            victim_queue = self.queues[victim_id]
            stolen_item = victim_queue.steal()

            if stolen_item:
                victim_queue.stats["stolen_from"] += 1
                return stolen_item

            attempts += 1

        return None

    async def _execute_task(self, item: WorkItem):
        """Execute task and set result/exception"""
        try:
            # Check if coroutine function
            if asyncio.iscoroutinefunction(item.func):
                result = await item.func(*item.args, **item.kwargs)
            else:
                # Run in executor for blocking functions
                loop = asyncio.get_event_loop()
                result = await loop.run_in_executor(None, item.func, *item.args, **item.kwargs)

            item.future.set_result(result)

        except Exception as e:
            item.future.set_exception(e)

    def stop(self):
        """Stop worker"""
        self.is_running = False


class WorkStealingPool:
    """
    Work-stealing thread pool with optimal CPU utilization
    """

    def __init__(self, num_workers: Optional[int] = None, numa_aware: bool = True):
        """
        Initialize work-stealing pool

        Args:
            num_workers: Number of workers (default: CPU count)
            numa_aware: Enable NUMA-aware allocation
        """
        self.num_workers = num_workers or multiprocessing.cpu_count()
        self.numa_aware = numa_aware

        # Create per-CPU work queues
        self.queues = [WorkQueue(cpu_id=i) for i in range(self.num_workers)]

        # Create workers
        self.workers = [WorkStealingWorker(i, self.num_workers, self.queues) for i in range(self.num_workers)]

        # Worker tasks
        self.worker_tasks: list[asyncio.Task] = []

        # Task ID counter
        self.task_counter = 0

        # NUMA topology (if available)
        self.numa_nodes = self._detect_numa_topology()

        # Pool statistics
        self.stats = {
            "total_tasks": 0,
            "completed_tasks": 0,
            "pending_tasks": 0,
            "total_queue_time_ms": 0,
            "avg_queue_time_ms": 0,
        }

        self.is_running = False

    def _detect_numa_topology(self) -> dict:
        """Detect NUMA topology"""
        numa_info = {"available": False, "nodes": 1, "cpus_per_node": {}}

        if not self.numa_aware:
            return numa_info

        try:
            # Try to detect NUMA using os
            if hasattr(os, "sched_getaffinity"):
                # Basic detection (could be enhanced with libnuma)
                numa_info["available"] = True
                numa_info["nodes"] = 1  # Assume single node for now
                numa_info["cpus_per_node"][0] = list(range(self.num_workers))

        except Exception:
            pass

        return numa_info

    async def start(self):
        """Start worker pool"""
        if not self.is_running:
            self.is_running = True

            # Start all workers
            for worker in self.workers:
                task = asyncio.create_task(worker.run())
                self.worker_tasks.append(task)

            print(f"ðŸŠ Work-stealing pool started ({self.num_workers} workers)")

    async def stop(self):
        """Stop worker pool"""
        if self.is_running:
            # Stop all workers
            for worker in self.workers:
                worker.stop()

            # Cancel worker tasks
            for task in self.worker_tasks:
                task.cancel()

            # Wait for cancellation
            await asyncio.gather(*self.worker_tasks, return_exceptions=True)

            self.worker_tasks.clear()
            self.is_running = False

    def submit(
        self,
        func: Callable,
        *args,
        priority: TaskPriority = TaskPriority.NORMAL,
        affinity: Optional[int] = None,
        **kwargs,
    ) -> Future:
        """
        Submit task to pool

        Args:
            func: Function to execute
            *args: Function arguments
            priority: Task priority
            affinity: CPU affinity hint (0 to num_workers-1)
            **kwargs: Function keyword arguments

        Returns:
            Future for task result
        """
        # Generate task ID
        self.task_counter += 1
        task_id = f"task_{self.task_counter}"

        # Create future
        future = Future()

        # Create work item
        work_item = WorkItem(
            task_id=task_id,
            func=func,
            args=args,
            kwargs=kwargs,
            priority=priority,
            affinity=affinity,
            future=future,
            enqueue_time=time.time(),
        )

        # Select queue based on affinity or round-robin
        if affinity is not None and 0 <= affinity < self.num_workers:
            queue_idx = affinity
        else:
            # Round-robin with random offset for load balancing
            queue_idx = (self.task_counter + random.randint(0, self.num_workers - 1)) % self.num_workers

        # Push to selected queue
        self.queues[queue_idx].push_local(work_item)

        # Update stats
        self.stats["total_tasks"] += 1
        self.stats["pending_tasks"] += 1

        # Track completion
        future.add_done_callback(lambda f: self._on_task_complete(work_item))

        return future

    def _on_task_complete(self, work_item: WorkItem):
        """Callback when task completes"""
        queue_time_ms = (time.time() - work_item.enqueue_time) * 1000

        self.stats["completed_tasks"] += 1
        self.stats["pending_tasks"] -= 1
        self.stats["total_queue_time_ms"] += queue_time_ms

        if self.stats["completed_tasks"] > 0:
            self.stats["avg_queue_time_ms"] = self.stats["total_queue_time_ms"] / self.stats["completed_tasks"]

    def get_stats(self) -> dict:
        """Get pool statistics"""
        return {
            "pool": self.stats,
            "queues": [{"cpu_id": q.cpu_id, "size": q.size(), "stats": q.stats} for q in self.queues],
            "workers": [{"worker_id": w.worker_id, "stats": w.stats} for w in self.workers],
            "numa": self.numa_nodes,
        }


# Global instance
_work_stealing_pool: Optional[WorkStealingPool] = None


def get_work_stealing_pool(num_workers: Optional[int] = None) -> WorkStealingPool:
    """Get global work-stealing pool instance"""
    global _work_stealing_pool
    if _work_stealing_pool is None:
        _work_stealing_pool = WorkStealingPool(num_workers=num_workers)
    return _work_stealing_pool
